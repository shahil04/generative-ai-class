{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07782960",
   "metadata": {},
   "source": [
    "## RAG Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052e0990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install Required Libraries\n",
    "# !pip install tf-keras\n",
    "# !pip install faiss-cpu \n",
    "# !pip install sentence-transformers\n",
    "# !pip install langchain\n",
    "# !pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17a0944f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\.conda\\envs\\aienv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\hp\\.conda\\envs\\aienv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Step 2: Prepare Your Documents\n",
    "documents = [\n",
    "    \"Python is a popular programming language.\",\n",
    "    \"The capital of France is Paris.\",\n",
    "    \"Machine learning is a subfield of AI.\",\n",
    "    \"The sun rises in the east.\",\n",
    "    \"Dogs are loyal animals.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa2bd616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create Embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "doc_embeddings = model.encode(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e975b423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03083171, -0.01335987, -0.00917531, ...,  0.12055378,\n",
       "         0.16613545,  0.02672417],\n",
       "       [ 0.10325699,  0.03042014,  0.02909579, ...,  0.05853161,\n",
       "         0.08585993, -0.00566981],\n",
       "       [-0.0233226 , -0.06490562,  0.07027888, ...,  0.09400347,\n",
       "         0.0365702 , -0.06815643],\n",
       "       [ 0.00168072,  0.09225351,  0.09049016, ..., -0.00386197,\n",
       "        -0.05938188,  0.03753841],\n",
       "       [-0.04950928, -0.04866851,  0.03528721, ...,  0.10845861,\n",
       "         0.1102818 , -0.00347945]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc92b767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Build FAISS Index\n",
    "dimension = doc_embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(doc_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be215c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Define a Simple RAG Function\n",
    "def rag_query(query, k=2):\n",
    "    query_embedding = model.encode([query])\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    \n",
    "    retrieved_docs = [documents[i] for i in indices[0]]\n",
    "    print(\"üîç Retrieved Docs:\")\n",
    "    for doc in retrieved_docs:\n",
    "        print(\"-\", doc)\n",
    "    \n",
    "    # Simulate \"generation\" by combining context\n",
    "    context = \" \".join(retrieved_docs)\n",
    "    generated_answer = f\"Based on the documents, here‚Äôs an answer:\\n{context}\"\n",
    "    return generated_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "394da0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Retrieved Docs:\n",
      "- Machine learning is a subfield of AI.\n",
      "- Python is a popular programming language.\n",
      "\n",
      "üß† RAG Response:\n",
      "Based on the documents, here‚Äôs an answer:\n",
      "Machine learning is a subfield of AI. Python is a popular programming language.\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Try a Query\n",
    "question = \"What is AI?\"\n",
    "response = rag_query(question)\n",
    "print(\"\\nüß† RAG Response:\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34458d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92488c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
